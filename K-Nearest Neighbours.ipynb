{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. K-Nearest Neighbors (KNN) is a classification algorithm. The central idea is that data points with similar attributes tend to fall into similar categories.\n",
    "2. the central idea behind the K-Nearest Neighbor algorithm : If you have a dataset of points where the class of each point is known, you can take a new point with an unknown class, find it’s nearest neighbors, and classify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.770329614269007\n",
      "38.897300677553446\n"
     ]
    }
   ],
   "source": [
    "#we’re going to be classifying movies as either good or bad. In our dataset, we’ve classified a movie as good if it had an IMDb rating of 7.0 or greater. \n",
    "#Every “good” movie will have a class of 1, while every bad movie will have a class of 0.\n",
    "\n",
    "mean_girls = [97, 17000000, False] # length, #budget # # directed by particular person\n",
    "the_shining = [146, 19000000, True] \n",
    "gone_with_the_wind = [238, 3977000, False] \n",
    "\n",
    "star_wars = [125, 1977] # length of movie, # release date\n",
    "raiders = [115, 1981]\n",
    "mean_girls = [97, 2004]\n",
    "\n",
    "# distance formulae\n",
    "def distance(movie1, movie2):\n",
    "    length_difference = (movie1[0] - movie2[0]) ** 2\n",
    "    year_difference = (movie1[1] - movie2[1]) ** 2\n",
    "    distance = (length_difference + year_difference) ** 0.5\n",
    "    return distance\n",
    "\n",
    "print(distance(star_wars, raiders))\n",
    "print(distance(star_wars, mean_girls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7000000.000008286\n",
      "6000000.000126083\n"
     ]
    }
   ],
   "source": [
    "star_wars = [125, 1977, 11000000] # movie length, release date, budget\n",
    "raiders = [115, 1981, 18000000]\n",
    "mean_girls = [97, 2004, 17000000]\n",
    "\n",
    "def distance(movie1, movie2):\n",
    "    squared_difference = 0\n",
    "    for i in range(len(movie1)):\n",
    "        squared_difference += (movie1[i] - movie2[i]) ** 2\n",
    "        final_distance = squared_difference ** 0.5\n",
    "    return final_distance\n",
    "\n",
    "print(distance(star_wars, raiders))\n",
    "print(distance(star_wars, mean_girls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.047619047619047616, 0.8492063492063492, 0.8650793650793651, 0.4523809523809524, 0.5634920634920635, 0.46825396825396826, 0.6666666666666666, 0.5476190476190477, 1.0, 0.36507936507936506, 0.6111111111111112, 0.8333333333333334, 0.42063492063492064, 0.0, 0.8253968253968254, 0.4523809523809524, 0.9523809523809523, 0.5873015873015873, 0.0, 0.6904761904761905]\n"
     ]
    }
   ],
   "source": [
    "# normalize the data\n",
    "\n",
    "release_dates = [1897.0, 1998.0, 2000.0, 1948.0, 1962.0, 1950.0, 1975.0, 1960.0, 2017.0, 1937.0, 1968.0, 1996.0, 1944.0, 1891.0, 1995.0, 1948.0, 2011.0, 1965.0, 1891.0, 1978.0]\n",
    "\n",
    "def min_max_normalize(lst):\n",
    "    minimum = min(lst)\n",
    "    maximum = max(lst)\n",
    "    normalized = []\n",
    "    \n",
    "    for value in lst:\n",
    "        normalized_num = (value - minimum) / (maximum - minimum)\n",
    "        normalized.append(normalized_num)\n",
    "    return normalized\n",
    "\n",
    "print(min_max_normalize(release_dates))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that our data has been normalized and we know how to find the distance between two points, we can begin classifying unknown data!\n",
    "\n",
    "To do this, we want to find the k nearest neighbors of the unclassified point. In a few exercises, we’ll learn how to properly choose k, but for now, let’s choose a number that seems somewhat reasonable. Let’s choose 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(movie1, movie2):\n",
    "  squared_difference = 0\n",
    "  for i in range(len(movie1)):\n",
    "    squared_difference += (movie1[i] - movie2[i]) ** 2\n",
    "  final_distance = squared_difference ** 0.5\n",
    "  return final_distance\n",
    "\n",
    "def classify(unknown, dataset, k):\n",
    "  distances = []\n",
    "  #Looping through all points in the dataset\n",
    "  for title in dataset:\n",
    "    movie = dataset[title]\n",
    "    distance_to_point = distance(movie, unknown)\n",
    "    #Adding the distance and point associated with that distance\n",
    "    distances.append([distance_to_point, title])\n",
    "  distances.sort()\n",
    "  #Taking only the k closest points\n",
    "  neighbors = distances[0:k]\n",
    "  return neighbors\n",
    "  \n",
    "print(classify([.4, .2, .9], movie_dataset, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(movie1, movie2):\n",
    "  squared_difference = 0\n",
    "  for i in range(len(movie1)):\n",
    "    squared_difference += (movie1[i] - movie2[i]) ** 2\n",
    "  final_distance = squared_difference ** 0.5\n",
    "  return final_distance\n",
    "\n",
    "def classify(unknown, dataset, labels, k):\n",
    "  distances = []\n",
    "  #Looping through all points in the dataset\n",
    "  for title in dataset:\n",
    "    movie = dataset[title]\n",
    "    distance_to_point = distance(movie, unknown)\n",
    "    #Adding the distance and point associated with that distance\n",
    "    distances.append([distance_to_point, title])\n",
    "  distances.sort()\n",
    "  #Taking only the k closest points\n",
    "  neighbors = distances[0:k]\n",
    "  num_good = 0\n",
    "  num_bad = 0\n",
    "  for neighbor in neighbors:\n",
    "    title = neighbor[1]\n",
    "    if labels[title] == 0:\n",
    "      num_bad += 1\n",
    "    elif labels[title] == 1:\n",
    "      num_good += 1\n",
    "  if num_good > num_bad:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "\n",
    "print(\"Call Me By Your Name\" in movie_dataset) \n",
    "my_movie = [350000, 132, 2017]\n",
    "\n",
    "normalized_my_movie = normalize_point(my_movie)\n",
    "\n",
    "classify(normalized_my_movie, movie_dataset, movie_labels, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance(movie1, movie2):\n",
    "  squared_difference = 0\n",
    "  for i in range(len(movie1)):\n",
    "    squared_difference += (movie1[i] - movie2[i]) ** 2\n",
    "  final_distance = squared_difference ** 0.5\n",
    "  return final_distance\n",
    "\n",
    "def classify(unknown, dataset, labels, k):\n",
    "  distances = []\n",
    "  #Looping through all points in the dataset\n",
    "  for title in dataset:\n",
    "    movie = dataset[title]\n",
    "    distance_to_point = distance(movie, unknown)\n",
    "    #Adding the distance and point associated with that distance\n",
    "    distances.append([distance_to_point, title])\n",
    "  distances.sort()\n",
    "  #Taking only the k closest points\n",
    "  neighbors = distances[0:k]\n",
    "  num_good = 0\n",
    "  num_bad = 0\n",
    "  for neighbor in neighbors:\n",
    "    title = neighbor[1]\n",
    "    if labels[title] == 0:\n",
    "      num_bad += 1\n",
    "    elif labels[title] == 1:\n",
    "      num_good += 1\n",
    "  if num_good > num_bad:\n",
    "    return 1\n",
    "  else:\n",
    "    return 0\n",
    "  \n",
    "print(validation_set[\"Bee Movie\"])\n",
    "print(validation_labels[\"Bee Movie\"])\n",
    "\n",
    "guess=classify(validation_set[\"Bee Movie\"], training_set, training_labels, 5)\n",
    "print(guess)\n",
    "if guess == validation_labels[\"Bee Movie\"]:\n",
    "  print(\"Correct!\")\n",
    "else:\n",
    "  print(\"Wrong!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 3)\n",
    "\n",
    "training_points = [\n",
    "  [0.5, 0.2, 0.1],\n",
    "  [0.9, 0.7, 0.3],\n",
    "  [0.4, 0.5, 0.7]\n",
    "]\n",
    " \n",
    "training_labels = [0, 1, 1]\n",
    "classifier.fit(training_points, training_labels)\n",
    "\n",
    "unknown_points = [\n",
    "  [0.2, 0.1, 0.7],\n",
    "  [0.4, 0.7, 0.6],\n",
    "  [0.5, 0.8, 0.1]\n",
    "]\n",
    " \n",
    "guesses = classifier.predict(unknown_points)\n",
    "guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "three different ways to define the distance between two points:\n",
    "\n",
    "Euclidean Distance\n",
    "Manhattan Distance\n",
    "Hamming Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.605551275463989\n",
      "7.810249675906654\n"
     ]
    }
   ],
   "source": [
    "# Euclidean distance\n",
    "\n",
    "def euclidean_distance(pt1, pt2):\n",
    "    distance = 0\n",
    "    for i in range(len(pt1)):\n",
    "        distance += (pt1[i] - pt2[i]) ** 2\n",
    "    return distance ** 0.5\n",
    "\n",
    "print(euclidean_distance([1, 2], [4, 0]))\n",
    "print(euclidean_distance([5, 4, 3], [1, 7, 9]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Manhattan distance\n",
    "def manhattan_distance(pt1, pt2):\n",
    "    distance = 0\n",
    "    for i in range(len(pt1)):\n",
    "        distance += abs(pt1[i]- pt2[i])\n",
    "        return distance\n",
    "\n",
    "print(manhattan_distance([1, 2], [4, 0]))\n",
    "print(manhattan_distance([5, 4, 3], [1, 7, 9]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Hamming Distance is another slightly different variation on the distance formula. Instead of finding the difference of each dimension, Hamming distance only cares about whether the dimensions are exactly equal.\n",
    "\n",
    "def hamming_distance(pt1, pt2):\n",
    "    distance = 0\n",
    "    for i in range(len(pt1)):\n",
    "        if pt1[i] != pt2[i]:\n",
    "            distance += 1\n",
    "    return distance\n",
    "print(hamming_distance([1, 2], [1, 100]))\n",
    "print(hamming_distance([5, 4, 9], [1, 7, 9]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
